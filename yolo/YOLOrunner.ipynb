{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG3HQJiC4HMd"
      },
      "source": [
        "# YOLO\n",
        "The goal of this notebook is to do transfer learning of Fishial´s already implemented YOLO model. We do this by using Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WL6B6r54hEQ",
        "outputId": "a8ab933c-694f-4313-d79a-55f4c3de97b6"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLTdW1qq39IM",
        "outputId": "f133fc27-f0cc-482c-8da0-ec42979d7a2d"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import requests\n",
        "import logging\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SKEsQWhvaGcz"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"../data_csv/\"\n",
        "timor_leste_data_path = os.path.join(DATA_DIR, \"timor-leste.csv\") # Annotation info for ground truth\n",
        "images_path = \"../data_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZRSrG-XZbGs",
        "outputId": "83c4dac0-bc02-46c2-9533-c8e4e5e2042e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total annotated images: 603\n",
            "Relevant images 248\n",
            "Unique final JPGs: 217\n"
          ]
        }
      ],
      "source": [
        "# Filter out relevant images\n",
        "relevant_species = ['Alectis ciliaris', 'Aphareus rutilans', 'Caranx ignobilis', 'Caranx lugubris', 'Caranx melampygus', 'Caranx sexfasciatus', 'Chirocentrus dorab', 'Chirocentrus nudus', 'Decapterus macrosoma', 'Elagatis bipinnulata', 'Epinephelus maculatus', 'Epinephelus radiatus', 'Etelis carbunculus', 'Gymnocranius grandoculis', 'Katsuwonus pelamis', 'Lethrinus atkinsoni', 'Lethrinus erythracanthus', 'Lethrinus obsoletus', 'Lethrinus ornatus', 'Lutjanus bohar', 'Lutjanus fulviflamma', 'Lutjanus fulvus', 'Lutjanus gibbus', 'Lutjanus johnii', 'Lutjanus kasmira', 'Lutjanus rivulatus', 'Lutjanus russellii', 'Lutjanus timoriensis', 'Monotaxis grandoculis', 'Psettodes erumei', 'Rastrelliger kanagurta', 'Sardinella albella', 'Scolopsis lineata', 'Scolopsis vosmeri', 'Scomberoides lysan', 'Scomberomorus commerson', 'Seriola dumerili', 'Variola albimarginata']\n",
        "\n",
        "# Read annotation info (Timor-leste)\n",
        "df_tl_ann = pd.read_csv(timor_leste_data_path, encoding=\"utf-8-sig\", header=0, skiprows=1)\n",
        "df_tl_ann = df_tl_ann[[\"image_file\", \"catch_name_en\", \"Species_name\", \"Family\"]]\n",
        "\n",
        "# Filter by species in relevant_species\n",
        "df_filtered = df_tl_ann[df_tl_ann[\"Species_name\"].isin(relevant_species)]\n",
        "\n",
        "# Keep only images that actually exist\n",
        "existing_files = set(os.listdir(images_path))\n",
        "\n",
        "df_filtered = df_filtered[df_filtered[\"image_file\"].isin(existing_files)]\n",
        "\n",
        "# Convert to list of filenames\n",
        "filtered_images= df_filtered[\"image_file\"].tolist()\n",
        "\n",
        "print(\"Total annotated images:\", len(df_tl_ann))\n",
        "print(\"Relevant images\", len(df_filtered))\n",
        "print(\"Unique final JPGs:\", len(set(filtered_images)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Species_name\n",
              "Rastrelliger faughni    133\n",
              "Decapterus               89\n",
              "Lutjanus gibbus          75\n",
              "Lutjanus timoriensis     23\n",
              "Caranx sexfasciatus      22\n",
              "                       ... \n",
              "Sufflamen sp.             1\n",
              "Acanthurus nigricans      1\n",
              "Lutjanus fulvus           1\n",
              "Siganus fuscescens        1\n",
              "Lethrinus mahsena         1\n",
              "Name: count, Length: 97, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Amount of species\n",
        "\n",
        "df_tl_ann['Species_name'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "10YcDKvLIXQP",
        "outputId": "0e357904-ebe7-4b7c-e8e1-c939c9d02ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.235  Python-3.12.10 torch-2.9.1+cu128 CPU (Intel Core i7-14700F)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=482\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    612178  ultralytics.nn.modules.head.Detect           [482, [64, 128, 256]]         \n",
            "YOLO11n summary: 181 layers, 2,771,346 parameters, 2,771,330 gradients, 7.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2.51.6 MB/s, size: 14.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\dataset\\train\\labels... 888 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 888/888 1.3Kit/s 0.7s0.1ss\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\dataset\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3.20.5 MB/s, size: 18.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\dataset\\valid\\labels... 92 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 92/92 1.4Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\dataset\\valid\\labels.cache\n",
            "Plotting labels to C:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\runs\\detect\\train\\labels.jpg... \n",
            "WARNING \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=2.1e-05, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\kienn\\Downloads\\Prosjektoppgave\\yolo\\runs\\detect\\train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/1         0G     0.7632      5.635      1.183         52        640: 5% ╸─────────── 3/56 4.2s/it 10.9s<3:45"
          ]
        }
      ],
      "source": [
        "# Load a pretrained YOLO11n model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data=\"dataset/data.yaml\",\n",
        "    epochs=1,\n",
        "    imgsz=640,\n",
        "    device=\"cpu\",\n",
        "    patience=50\n",
        ")\n",
        "\n",
        "# Evaluate the model's performance on the validation set\n",
        "metrics = model.val()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(Image(filename=\"runs/classify/train/results.png\"))\n",
        "display(Image(filename=\"runs/classify/val/confusion_matrix.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x480 (no detections), 0.8ms\n",
            "1: 480x480 2 caranx_ignobiliss, 2 pomadasys_argenteuss, 0.8ms\n",
            "2: 480x480 1 pomadasys_kaakan, 0.8ms\n",
            "3: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "4: 480x480 (no detections), 0.8ms\n",
            "5: 480x480 1 chirocentrus_dorab, 0.8ms\n",
            "6: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "7: 480x480 1 parupeneus_heptacanthus, 0.8ms\n",
            "8: 480x480 1 lutjanus_johnii, 1 pomadasys_kaakan, 0.8ms\n",
            "9: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "10: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "11: 480x480 1 acanthocybium_solandri, 0.8ms\n",
            "12: 480x480 1 chirocentrus_dorab, 0.8ms\n",
            "13: 480x480 1 chirocentrus_dorab, 1 decapterus_macarellus, 0.8ms\n",
            "14: 480x480 1 decapterus_macarellus, 0.8ms\n",
            "15: 480x480 (no detections), 0.8ms\n",
            "16: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "17: 480x480 (no detections), 0.8ms\n",
            "18: 480x480 (no detections), 0.8ms\n",
            "19: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "20: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "21: 480x480 1 gymnocranius_grandoculis, 1 lutjanus_johnii, 0.8ms\n",
            "22: 480x480 5 gazza_minutas, 0.8ms\n",
            "23: 480x480 5 gazza_minutas, 0.8ms\n",
            "24: 480x480 (no detections), 0.8ms\n",
            "25: 480x480 (no detections), 0.8ms\n",
            "26: 480x480 (no detections), 0.8ms\n",
            "27: 480x480 4 lutjanus_johniis, 3 parupeneus_heptacanthuss, 0.8ms\n",
            "28: 480x480 4 parupeneus_heptacanthuss, 0.8ms\n",
            "29: 480x480 4 parupeneus_heptacanthuss, 0.8ms\n",
            "30: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "31: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "32: 480x480 1 chirocentrus_dorab, 0.8ms\n",
            "33: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "34: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "35: 480x480 1 parupeneus_heptacanthus, 0.8ms\n",
            "36: 480x480 1 parupeneus_heptacanthus, 0.8ms\n",
            "37: 480x480 1 parupeneus_heptacanthus, 0.8ms\n",
            "38: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "39: 480x480 6 gazza_minutas, 0.8ms\n",
            "40: 480x480 6 gazza_minutas, 0.8ms\n",
            "41: 480x480 (no detections), 0.8ms\n",
            "42: 480x480 (no detections), 0.8ms\n",
            "43: 480x480 (no detections), 0.8ms\n",
            "44: 480x480 1 parupeneus_heptacanthus, 1 variola_albimarginata, 0.8ms\n",
            "45: 480x480 1 scomberoides_tol, 0.8ms\n",
            "46: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "47: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "48: 480x480 (no detections), 0.8ms\n",
            "49: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "50: 480x480 (no detections), 0.8ms\n",
            "51: 480x480 (no detections), 0.8ms\n",
            "52: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "53: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "54: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "55: 480x480 1 variola_albimarginata, 0.8ms\n",
            "56: 480x480 (no detections), 0.8ms\n",
            "57: 480x480 1 gazza_minuta, 3 lujanus_gibbuss, 0.8ms\n",
            "58: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "59: 480x480 (no detections), 0.8ms\n",
            "60: 480x480 2 lutjanus_johniis, 0.8ms\n",
            "61: 480x480 3 lutjanus_johniis, 1 pomadasys_kaakan, 0.8ms\n",
            "62: 480x480 2 pomadasys_kaakans, 0.8ms\n",
            "63: 480x480 1 variola_albimarginata, 0.8ms\n",
            "64: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "65: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "66: 480x480 (no detections), 0.8ms\n",
            "67: 480x480 1 parupeneus_heptacanthus, 0.8ms\n",
            "68: 480x480 (no detections), 0.8ms\n",
            "69: 480x480 2 parupeneus_heptacanthuss, 0.8ms\n",
            "70: 480x480 1 parupeneus_heptacanthus, 3 parupeneus_indicuss, 0.8ms\n",
            "71: 480x480 1 caranx_ignobilis, 1 scomberomorus_commerson, 0.8ms\n",
            "72: 480x480 1 caranx_ignobilis, 1 scomberomorus_commerson, 0.8ms\n",
            "73: 480x480 1 caranx_ignobilis, 2 gazza_minutas, 5 scomberomorus_commersons, 0.8ms\n",
            "74: 480x480 1 caranx_ignobilis, 2 gazza_minutas, 5 scomberomorus_commersons, 0.8ms\n",
            "75: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "76: 480x480 1 parupeneus_heptacanthus, 3 parupeneus_indicuss, 0.8ms\n",
            "77: 480x480 2 pomadasys_kaakans, 0.8ms\n",
            "78: 480x480 (no detections), 0.8ms\n",
            "79: 480x480 1 acanthocybium_solandri, 0.8ms\n",
            "80: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "81: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "82: 480x480 2 caranx_ignobiliss, 0.8ms\n",
            "83: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "84: 480x480 1 caranx_ignobilis, 1 pomadasys_kaakan, 0.8ms\n",
            "85: 480x480 (no detections), 0.8ms\n",
            "86: 480x480 1 aurigequula_fasciata, 1 caranx_ignobilis, 0.8ms\n",
            "87: 480x480 2 chirocentrus_dorabs, 0.8ms\n",
            "88: 480x480 2 chirocentrus_dorabs, 0.8ms\n",
            "89: 480x480 2 scomberomorus_commersons, 0.8ms\n",
            "90: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "91: 480x480 (no detections), 0.8ms\n",
            "92: 480x480 (no detections), 0.8ms\n",
            "93: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "94: 480x480 (no detections), 0.8ms\n",
            "95: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "96: 480x480 2 chirocentrus_dorabs, 0.8ms\n",
            "97: 480x480 2 acanthocybium_solandris, 0.8ms\n",
            "98: 480x480 2 chirocentrus_dorabs, 0.8ms\n",
            "99: 480x480 2 chirocentrus_dorabs, 0.8ms\n",
            "100: 480x480 (no detections), 0.8ms\n",
            "101: 480x480 (no detections), 0.8ms\n",
            "102: 480x480 (no detections), 0.8ms\n",
            "103: 480x480 (no detections), 0.8ms\n",
            "104: 480x480 (no detections), 0.8ms\n",
            "105: 480x480 (no detections), 0.8ms\n",
            "106: 480x480 1 chirocentrus_dorab, 6 gazza_minutas, 0.8ms\n",
            "107: 480x480 (no detections), 0.8ms\n",
            "108: 480x480 (no detections), 0.8ms\n",
            "109: 480x480 (no detections), 0.8ms\n",
            "110: 480x480 2 gazza_minutas, 1 lujanus_gibbus, 0.8ms\n",
            "111: 480x480 3 lutjanus_fulvuss, 1 lutjanus_johnii, 0.8ms\n",
            "112: 480x480 1 lutjanus_johnii, 2 pomadasys_argenteuss, 0.8ms\n",
            "113: 480x480 1 lutjanus_fulviflamma, 0.8ms\n",
            "114: 480x480 2 rastrelliger_kanagurtas, 0.8ms\n",
            "115: 480x480 2 chirocentrus_dorabs, 0.8ms\n",
            "116: 480x480 1 gymnocranius_grandoculis, 0.8ms\n",
            "117: 480x480 3 parupeneus_heptacanthuss, 1 upeneus_vittatus, 0.8ms\n",
            "118: 480x480 1 pomadasys_kaakan, 0.8ms\n",
            "119: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "120: 480x480 (no detections), 0.8ms\n",
            "121: 480x480 (no detections), 0.8ms\n",
            "122: 480x480 (no detections), 0.8ms\n",
            "123: 480x480 1 lutjanus_fulvus, 0.8ms\n",
            "124: 480x480 (no detections), 0.8ms\n",
            "125: 480x480 (no detections), 0.8ms\n",
            "126: 480x480 (no detections), 0.8ms\n",
            "127: 480x480 (no detections), 0.8ms\n",
            "128: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "129: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "130: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "131: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "132: 480x480 1 lutjanus_johnii, 1 parupeneus_heptacanthus, 0.8ms\n",
            "133: 480x480 (no detections), 0.8ms\n",
            "134: 480x480 3 lutjanus_johniis, 0.8ms\n",
            "135: 480x480 (no detections), 0.8ms\n",
            "136: 480x480 1 lutjanus_fulvus, 3 scomberoides_tols, 0.8ms\n",
            "137: 480x480 5 scomberoides_tols, 1 upeneus_vittatus, 0.8ms\n",
            "138: 480x480 8 lutjanus_fulvuss, 0.8ms\n",
            "139: 480x480 11 lutjanus_fulvuss, 0.8ms\n",
            "140: 480x480 (no detections), 0.8ms\n",
            "141: 480x480 5 lujanus_gibbuss, 2 pomadasys_argenteuss, 0.8ms\n",
            "142: 480x480 5 lujanus_gibbuss, 2 pomadasys_argenteuss, 0.8ms\n",
            "143: 480x480 1 alectis_ciliaris, 0.8ms\n",
            "144: 480x480 (no detections), 0.8ms\n",
            "145: 480x480 (no detections), 0.8ms\n",
            "146: 480x480 (no detections), 0.8ms\n",
            "147: 480x480 3 lutjanus_johniis, 0.8ms\n",
            "148: 480x480 (no detections), 0.8ms\n",
            "149: 480x480 (no detections), 0.8ms\n",
            "150: 480x480 3 lutjanus_johniis, 1 parupeneus_heptacanthus, 1 pomadasys_argenteus, 0.8ms\n",
            "151: 480x480 5 lutjanus_fulvuss, 5 lutjanus_johniis, 0.8ms\n",
            "152: 480x480 5 lutjanus_fulvuss, 5 lutjanus_johniis, 0.8ms\n",
            "153: 480x480 3 lutjanus_johniis, 1 parupeneus_heptacanthus, 0.8ms\n",
            "154: 480x480 (no detections), 0.8ms\n",
            "155: 480x480 1 scomberoides_tol, 0.8ms\n",
            "156: 480x480 1 scomberoides_tol, 0.8ms\n",
            "157: 480x480 1 aurigequula_fasciata, 1 gazza_minuta, 0.8ms\n",
            "158: 480x480 (no detections), 0.8ms\n",
            "159: 480x480 1 lutjanus_fulvus, 0.8ms\n",
            "160: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "161: 480x480 1 scomberoides_tol, 0.8ms\n",
            "162: 480x480 1 lutjanus_fulvus, 0.8ms\n",
            "163: 480x480 (no detections), 0.8ms\n",
            "164: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "165: 480x480 (no detections), 0.8ms\n",
            "166: 480x480 (no detections), 0.8ms\n",
            "167: 480x480 (no detections), 0.8ms\n",
            "168: 480x480 (no detections), 0.8ms\n",
            "169: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "170: 480x480 (no detections), 0.8ms\n",
            "171: 480x480 (no detections), 0.8ms\n",
            "172: 480x480 (no detections), 0.8ms\n",
            "173: 480x480 (no detections), 0.8ms\n",
            "174: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "175: 480x480 (no detections), 0.8ms\n",
            "176: 480x480 (no detections), 0.8ms\n",
            "177: 480x480 (no detections), 0.8ms\n",
            "178: 480x480 (no detections), 0.8ms\n",
            "179: 480x480 (no detections), 0.8ms\n",
            "180: 480x480 1 chirocentrus_dorab, 0.8ms\n",
            "181: 480x480 (no detections), 0.8ms\n",
            "182: 480x480 1 lutjanus_fulvus, 2 upeneus_vittatuss, 0.8ms\n",
            "183: 480x480 2 rastrelliger_kanagurtas, 0.8ms\n",
            "184: 480x480 (no detections), 0.8ms\n",
            "185: 480x480 (no detections), 0.8ms\n",
            "186: 480x480 1 pomadasys_argenteus, 0.8ms\n",
            "187: 480x480 (no detections), 0.8ms\n",
            "188: 480x480 (no detections), 0.8ms\n",
            "189: 480x480 (no detections), 0.8ms\n",
            "190: 480x480 1 mulloidichtys_vanicolensis, 0.8ms\n",
            "191: 480x480 (no detections), 0.8ms\n",
            "192: 480x480 (no detections), 0.8ms\n",
            "193: 480x480 2 lutjanus_fulvuss, 1 rastrelliger_kanagurta, 2 upeneus_vittatuss, 0.8ms\n",
            "194: 480x480 (no detections), 0.8ms\n",
            "195: 480x480 2 lutjanus_johniis, 4 parupeneus_heptacanthuss, 0.8ms\n",
            "196: 480x480 (no detections), 0.8ms\n",
            "197: 480x480 7 parupeneus_heptacanthuss, 0.8ms\n",
            "198: 480x480 1 lutjanus_fulviflamma, 1 lutjanus_johnii, 4 parupeneus_heptacanthuss, 0.8ms\n",
            "199: 480x480 1 lutjanus_fulviflamma, 1 lutjanus_johnii, 4 parupeneus_heptacanthuss, 0.8ms\n",
            "200: 480x480 2 lutjanus_johniis, 4 parupeneus_heptacanthuss, 0.8ms\n",
            "201: 480x480 (no detections), 0.8ms\n",
            "202: 480x480 4 lutjanus_johniis, 1 parupeneus_heptacanthus, 0.8ms\n",
            "203: 480x480 4 lutjanus_johniis, 1 parupeneus_heptacanthus, 0.8ms\n",
            "204: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "205: 480x480 1 pomadasys_argenteus, 0.8ms\n",
            "206: 480x480 2 lutjanus_fulvuss, 1 scomberoides_tol, 0.8ms\n",
            "207: 480x480 (no detections), 0.8ms\n",
            "208: 480x480 2 lutjanus_johniis, 1 parupeneus_heptacanthus, 0.8ms\n",
            "209: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "210: 480x480 2 lutjanus_johniis, 0.8ms\n",
            "211: 480x480 1 lutjanus_johnii, 2 parupeneus_heptacanthuss, 0.8ms\n",
            "212: 480x480 2 lutjanus_johniis, 3 parupeneus_heptacanthuss, 1 pristigenys_niphonia, 0.8ms\n",
            "213: 480x480 (no detections), 0.8ms\n",
            "214: 480x480 (no detections), 0.8ms\n",
            "215: 480x480 1 lutjanus_fulvus, 2 lutjanus_johniis, 1 scomberoides_tol, 0.8ms\n",
            "216: 480x480 4 lutjanus_fulvuss, 1 lutjanus_johnii, 0.8ms\n",
            "217: 480x480 (no detections), 0.8ms\n",
            "218: 480x480 (no detections), 0.8ms\n",
            "219: 480x480 (no detections), 0.8ms\n",
            "220: 480x480 (no detections), 0.8ms\n",
            "221: 480x480 (no detections), 0.8ms\n",
            "222: 480x480 (no detections), 0.8ms\n",
            "223: 480x480 1 parupeneus_heptacanthus, 0.8ms\n",
            "224: 480x480 (no detections), 0.8ms\n",
            "225: 480x480 (no detections), 0.8ms\n",
            "226: 480x480 (no detections), 0.8ms\n",
            "227: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "228: 480x480 (no detections), 0.8ms\n",
            "229: 480x480 3 lutjanus_johniis, 0.8ms\n",
            "230: 480x480 4 lutjanus_johniis, 0.8ms\n",
            "231: 480x480 3 lutjanus_johniis, 2 pomadasys_kaakans, 0.8ms\n",
            "232: 480x480 3 lutjanus_johniis, 0.8ms\n",
            "233: 480x480 3 lutjanus_johniis, 0.8ms\n",
            "234: 480x480 2 lutjanus_johniis, 0.8ms\n",
            "235: 480x480 (no detections), 0.8ms\n",
            "236: 480x480 4 lujanus_gibbuss, 2 lutjanus_fulvuss, 2 lutjanus_kasmiras, 2 pomadasys_argenteuss, 0.8ms\n",
            "237: 480x480 1 lutjanus_fulviflamma, 0.8ms\n",
            "238: 480x480 (no detections), 0.8ms\n",
            "239: 480x480 (no detections), 0.8ms\n",
            "240: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "241: 480x480 1 caranx_ignobilis, 0.8ms\n",
            "242: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "243: 480x480 1 lutjanus_johnii, 0.8ms\n",
            "244: 480x480 2 gymnocranius_grandoculiss, 0.8ms\n",
            "245: 480x480 2 gymnocranius_grandoculiss, 0.8ms\n",
            "246: 480x480 2 gymnocranius_grandoculiss, 0.8ms\n",
            "247: 480x480 1 scomberomorus_commerson, 0.8ms\n",
            "Speed: 1.2ms preprocess, 0.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 480)\n",
            "Match summary:\n",
            " match\n",
            "MISMATCH        404\n",
            "NO_DETECTION     90\n",
            "MATCH             5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Saved merged file with matches to: predictions_with_groundtruth_matches_first.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ---------- config ----------\n",
        "MODEL_PATH = \"runs/detect/train4/weights/best.pt\"  # path to your trained model\n",
        "IMAGE_PATHS = [os.path.join(\"../data_images/\", f) for f in filtered_images]  # filtered_images must exist\n",
        "CSV_OUT = \"predictions_with_groundtruth_matches_first.csv\"\n",
        "GT_FILENAME_COL = \"image_file\"          # column in df_tl_ann to join on\n",
        "GT_SPECIES_COL = \"Species_name\"       # ground truth species column name in df_tl_ann\n",
        "# ----------------------------\n",
        "\n",
        "# Load model\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# Run predictions (you can tune imgsz, conf, etc.)\n",
        "results = model.predict(source=IMAGE_PATHS, imgsz=480)\n",
        "\n",
        "# Build predictions dataframe\n",
        "pred_rows = []\n",
        "for r in results:\n",
        "    image_name = os.path.basename(r.path)\n",
        "    boxes = getattr(r, \"boxes\", None)\n",
        "\n",
        "    if boxes is None or len(boxes) == 0:\n",
        "        pred_rows.append({\n",
        "            \"image_file\": image_name,\n",
        "            \"pred_class\": None,\n",
        "            \"pred_conf\": None,\n",
        "            \"pred_x1\": None,\n",
        "            \"pred_y1\": None,\n",
        "            \"pred_x2\": None,\n",
        "            \"pred_y2\": None,\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    xyxy = boxes.xyxy.cpu().numpy()\n",
        "    scores = boxes.conf.cpu().numpy()\n",
        "    classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "    for (x1, y1, x2, y2), conf, cls in zip(xyxy, scores, classes):\n",
        "        pred_rows.append({\n",
        "            \"image_file\": image_name,\n",
        "            \"pred_class\": model.names[int(cls)] if cls is not None else None,\n",
        "            \"pred_conf\": float(conf),\n",
        "            \"pred_x1\": int(x1),\n",
        "            \"pred_y1\": int(y1),\n",
        "            \"pred_x2\": int(x2),\n",
        "            \"pred_y2\": int(y2),\n",
        "        })\n",
        "\n",
        "df_preds = pd.DataFrame(pred_rows)\n",
        "\n",
        "# ---------- load ground truth ----------\n",
        "# If df_tl_ann is not already loaded, load it here, e.g.:\n",
        "# df_tl_ann = pd.read_csv(\"timor_leste_annotations.csv\")\n",
        "# Ensure it contains the expected columns\n",
        "if GT_FILENAME_COL not in df_tl_ann.columns:\n",
        "    raise KeyError(f\"Ground truth dataframe must contain column '{GT_FILENAME_COL}'\")\n",
        "if GT_SPECIES_COL not in df_tl_ann.columns:\n",
        "    raise KeyError(f\"Ground truth dataframe must contain species column '{GT_SPECIES_COL}'\")\n",
        "\n",
        "# If ground truth has multiple rows per filename (multiple labeled fish per image),\n",
        "# aggregate species into a list per filename to allow matching any of them.\n",
        "df_gt_grouped = (\n",
        "    df_tl_ann\n",
        "    .groupby(GT_FILENAME_COL)[GT_SPECIES_COL]\n",
        "    .apply(lambda s: list(s.dropna().astype(str)))\n",
        "    .reset_index()\n",
        "    .rename(columns={GT_SPECIES_COL: \"gt_species_list\"})\n",
        ")\n",
        "\n",
        "# Merge predictions with grouped ground truth (left join keeps predictions even if no GT)\n",
        "df_merged = df_preds.merge(df_gt_grouped, on=\"image_file\", how=\"left\")\n",
        "\n",
        "# ---------- helper for normalization ----------\n",
        "def normalize_name(s):\n",
        "    if pd.isna(s) or s is None:\n",
        "        return \"\"\n",
        "    # lowercase, strip whitespace, replace underscores, collapse multiple spaces\n",
        "    s2 = str(s).lower().strip().replace(\"_\", \" \")\n",
        "    s2 = \" \".join(s2.split())\n",
        "    return s2\n",
        "\n",
        "# Normalize GT species lists & prediction class for comparison\n",
        "df_merged[\"pred_class_norm\"] = df_merged[\"pred_class\"].apply(normalize_name)\n",
        "df_merged[\"gt_species_norm_list\"] = df_merged[\"gt_species_list\"].apply(\n",
        "    lambda lst: [normalize_name(x) for x in lst] if isinstance(lst, list) else []\n",
        ")\n",
        "\n",
        "# ---------- compute match column ----------\n",
        "def compare_row(row):\n",
        "    pred = row[\"pred_class_norm\"]\n",
        "    gt_list = row[\"gt_species_norm_list\"]\n",
        "\n",
        "    if (pred == \"\" or pred is None) and (not gt_list):\n",
        "        # no detection and no gt\n",
        "        return \"NO_DETECTION_AND_NO_GT\"\n",
        "    if pred == \"\" or pred is None:\n",
        "        # no detection but GT exists\n",
        "        return \"NO_DETECTION\"\n",
        "    if not gt_list:\n",
        "        # prediction exists but no ground truth\n",
        "        return \"NO_GT\"\n",
        "    # if any exact match in normalized strings:\n",
        "    if pred in gt_list:\n",
        "        return \"MATCH\"\n",
        "    # optionally: fuzzy matching can be done here (e.g., substring/in operator)\n",
        "    # try substring match (pred contained in any gt or vice versa)\n",
        "    for g in gt_list:\n",
        "        if pred in g or g in pred:\n",
        "            return \"MATCH_SUBSTRING\"\n",
        "    return \"MISMATCH\"\n",
        "\n",
        "df_merged[\"match\"] = df_merged.apply(compare_row, axis=1)\n",
        "\n",
        "# ---------- optional: summary stats ----------\n",
        "summary = df_merged[\"match\"].value_counts(dropna=False)\n",
        "print(\"Match summary:\\n\", summary)\n",
        "\n",
        "# Save to CSV\n",
        "df_merged.to_csv(CSV_OUT, index=False)\n",
        "print(f\"\\nSaved merged file with matches to: {CSV_OUT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total GT rows: 603\n",
            "Images with >=1 matching prediction: 5 (0.83%)\n",
            "Images with multiple predictions (>1): 147\n",
            "Images with zero predictions: 319\n",
            "\n",
            "Example rows (image_file, gt_norm_list, predicted_list, preds_norm, match_any):\n",
            "       image_file           gt_norm_list                                                                 predicted_list                                                                     preds_norm  match_any\n",
            "1689120590238.jpg  [Caranx sexfasciatus]                                                                          [Nan]                                                                          [Nan]      False\n",
            "1689254343092.jpg         [Gazza minuta]                                                                             []                                                                             []      False\n",
            "1689254343092.jpg     [Upeneus vittatus]                                                                             []                                                                             []      False\n",
            "1689379821579.jpg           [Decapterus]                                                                             []                                                                             []      False\n",
            "1689388044927.jpg      [Caranx lugubris] [Pomadasys argenteus, Caranx ignobilis, Pomadasys argenteus, Caranx ignobilis] [Pomadasys argenteus, Caranx ignobilis, Pomadasys argenteus, Caranx ignobilis]      False\n",
            "1689388326411.jpg      [Caranx lugubris]                                                             [Pomadasys kaakan]                                                             [Pomadasys kaakan]      False\n",
            "1689421223571.jpg [Rastrelliger faughni]                                                                             []                                                                             []      False\n",
            "1689556573003.jpg [Rastrelliger faughni]                                                                             []                                                                             []      False\n",
            "1689556897897.jpg [Rastrelliger faughni]                                                                             []                                                                             []      False\n",
            "1689557063983.jpg [Lutjanus timoriensis]                                                              [Lutjanus johnii]                                                              [Lutjanus johnii]      False\n",
            "\n",
            "Saved analysis to: gt_vs_preds_analysis_converted_first.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pathlib\n",
        "import ast\n",
        "import re\n",
        "\n",
        "# ----------------- USER ADJUSTABLE VARIABLES -----------------\n",
        "# Provide GT (path or DataFrame). Example uses your variable name:\n",
        "gt_input = pd.read_csv(timor_leste_data_path, encoding=\"utf-8-sig\", header=0, skiprows=1)\n",
        "\n",
        "# Predictions CSV path or DataFrame\n",
        "preds_input = \"predictions_with_groundtruth_matches_first.csv\"\n",
        "\n",
        "# Column names used in your files\n",
        "gt_image_col = \"image_file\"\n",
        "gt_species_col = \"Species_name\"\n",
        "preds_image_col = \"image_file\"\n",
        "preds_class_col = \"pred_class\"   # one-row-per-detection format (optional)\n",
        "preds_list_col = \"pred_list\"     # one-row-per-image list column (optional)\n",
        "\n",
        "# Choose Title case for predictions\n",
        "PRED_CASE = \"title\"\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# ----------------- Helper functions -----------------\n",
        "def title_case_name(s):\n",
        "    \"\"\"Return string in 'Genus species' style: Genus capitalized, rest lowercased.\"\"\"\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = str(s).strip()\n",
        "    # collapse whitespace and separators\n",
        "    s = re.sub(r\"[ _\\-\\.\\s]+\", \" \", s).strip()\n",
        "    parts = s.split()\n",
        "    if len(parts) >= 2:\n",
        "        return parts[0].capitalize() + \" \" + \" \".join(p.lower() for p in parts[1:])\n",
        "    return s.capitalize()\n",
        "\n",
        "def normalize_label_title(x):\n",
        "    \"\"\"Normalize input to Title Case for consistent comparison.\"\"\"\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    return title_case_name(x)\n",
        "\n",
        "def snake_or_token_to_name(token: str, case=\"title\"):\n",
        "    \"\"\"Convert tokens like 'scomberomorus_commerson' to Title Case or raw string.\"\"\"\n",
        "    if token is None:\n",
        "        return \"\"\n",
        "    s = str(token).strip().strip(\"'\\\"\")\n",
        "    s = re.sub(r\"[ _\\-\\.\\s]+\", \" \", s).strip()\n",
        "    if case == \"lower\":\n",
        "        return s.lower()\n",
        "    if case == \"title\":\n",
        "        return title_case_name(s)\n",
        "    return s\n",
        "\n",
        "def parse_pred_list_cell(val, case=\"title\"):\n",
        "    \"\"\"\n",
        "    Robust parse for pred list cells -> returns list of converted labels in chosen case.\n",
        "    \"\"\"\n",
        "    if val is None or (isinstance(val, float) and pd.isna(val)):\n",
        "        return []\n",
        "    if isinstance(val, (list, tuple)):\n",
        "        return [snake_or_token_to_name(x, case=case) for x in val]\n",
        "    s = str(val).strip()\n",
        "    # try safe literal eval\n",
        "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
        "        try:\n",
        "            parsed = ast.literal_eval(s)\n",
        "            if isinstance(parsed, (list, tuple)):\n",
        "                return [snake_or_token_to_name(x, case=case) for x in parsed]\n",
        "        except Exception:\n",
        "            pass\n",
        "    # separators\n",
        "    if \"|\" in s:\n",
        "        parts = [p.strip() for p in s.split(\"|\") if p.strip()]\n",
        "        return [snake_or_token_to_name(x, case=case) for x in parts]\n",
        "    if \",\" in s:\n",
        "        parts = [p.strip() for p in s.split(\",\") if p.strip()]\n",
        "        return [snake_or_token_to_name(x, case=case) for x in parts]\n",
        "    return [snake_or_token_to_name(s, case=case)]\n",
        "\n",
        "# ----------------- Load inputs -----------------\n",
        "def load_gt(gt_input):\n",
        "    if isinstance(gt_input, pd.DataFrame):\n",
        "        return gt_input.copy()\n",
        "    if isinstance(gt_input, (str, pathlib.Path)):\n",
        "        return pd.read_csv(str(gt_input))\n",
        "    if hasattr(gt_input, \"read\") and callable(getattr(gt_input, \"read\")):\n",
        "        return pd.read_csv(gt_input)\n",
        "    raise TypeError(\"gt_input must be a DataFrame, filename (str/Path), or file-like object.\")\n",
        "\n",
        "def load_preds(preds_input):\n",
        "    if isinstance(preds_input, pd.DataFrame):\n",
        "        return preds_input.copy()\n",
        "    if isinstance(preds_input, (str, pathlib.Path)):\n",
        "        return pd.read_csv(str(preds_input))\n",
        "    if hasattr(preds_input, \"read\") and callable(getattr(preds_input, \"read\")):\n",
        "        return pd.read_csv(preds_input)\n",
        "    raise TypeError(\"preds_input must be a DataFrame, filename (str/Path), or file-like object.\")\n",
        "\n",
        "gt = load_gt(gt_input)\n",
        "preds_df = load_preds(preds_input)\n",
        "\n",
        "# Normalize image filename columns\n",
        "gt[gt_image_col] = gt[gt_image_col].astype(str).str.strip()\n",
        "preds_df[preds_image_col] = preds_df[preds_image_col].astype(str).str.strip()\n",
        "\n",
        "# ----------------- Prepare ground-truth lists (Title Case) -----------------\n",
        "def split_gt_species(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    s = str(s)\n",
        "    for sep in [\" & \", \"&\", \"/\", \";\", \",\", \"|\"]:\n",
        "        s = s.replace(sep, \" | \")\n",
        "    parts = [p.strip() for p in s.split(\"|\") if p.strip()]\n",
        "    return parts\n",
        "\n",
        "gt[\"gt_list\"] = gt[gt_species_col].apply(split_gt_species)\n",
        "# Normalize GT list to Title Case\n",
        "gt[\"gt_norm_list\"] = gt[\"gt_list\"].apply(lambda lst: [normalize_label_title(x) for x in lst])\n",
        "\n",
        "# ----------------- Prepare predictions grouped per image (converted to Title Case) -----------------\n",
        "if preds_class_col in preds_df.columns:\n",
        "    # convert token labels in pred_class directly to Title Case, then group\n",
        "    preds_df[\"_pred_converted\"] = preds_df[preds_class_col].apply(lambda v: snake_or_token_to_name(v, case=PRED_CASE))\n",
        "    preds_grouped = preds_df.groupby(preds_image_col)[\"_pred_converted\"].apply(list).reset_index()\n",
        "    preds_grouped.columns = [preds_image_col, \"predicted_list\"]\n",
        "elif preds_list_col in preds_df.columns:\n",
        "    preds_grouped = preds_df[[preds_image_col, preds_list_col]].copy()\n",
        "    preds_grouped[\"predicted_list\"] = preds_grouped[preds_list_col].apply(lambda v: parse_pred_list_cell(v, case=PRED_CASE))\n",
        "    preds_grouped = preds_grouped[[preds_image_col, \"predicted_list\"]]\n",
        "else:\n",
        "    # fallback search for commonly named columns\n",
        "    fallback_names = [\"predicted_list\", \"predictions\", \"preds\"]\n",
        "    found = False\n",
        "    for name in fallback_names:\n",
        "        if name in preds_df.columns:\n",
        "            preds_grouped = preds_df[[preds_image_col, name]].copy()\n",
        "            preds_grouped[\"predicted_list\"] = preds_grouped[name].apply(lambda v: parse_pred_list_cell(v, case=PRED_CASE))\n",
        "            preds_grouped = preds_grouped[[preds_image_col, \"predicted_list\"]]\n",
        "            found = True\n",
        "            break\n",
        "    if not found:\n",
        "        raise ValueError(f\"Predictions must contain either '{preds_class_col}' or '{preds_list_col}' or one of {fallback_names}.\")\n",
        "\n",
        "# ----------------- Merge and compute matches -----------------\n",
        "merged = pd.merge(\n",
        "    gt[[gt_image_col, gt_species_col, \"gt_list\", \"gt_norm_list\"]],\n",
        "    preds_grouped,\n",
        "    how=\"left\",\n",
        "    left_on=gt_image_col,\n",
        "    right_on=preds_image_col\n",
        ")\n",
        "\n",
        "# ensure predicted_list is a real list\n",
        "merged[\"predicted_list\"] = merged[\"predicted_list\"].apply(lambda x: x if isinstance(x, list) else ([] if pd.isna(x) else list(x)))\n",
        "# Normalize predicted labels to Title Case for preds_norm (ensures Title)\n",
        "merged[\"preds_norm\"] = merged[\"predicted_list\"].apply(lambda lst: [normalize_label_title(p) for p in lst])\n",
        "\n",
        "def any_match(gt_norm_list, preds_norm_list):\n",
        "    if not gt_norm_list:\n",
        "        return False\n",
        "    return any((g == p) for g in gt_norm_list for p in preds_norm_list)\n",
        "\n",
        "merged[\"match_any\"] = merged.apply(lambda r: any_match(r[\"gt_norm_list\"], r[\"preds_norm\"]), axis=1)\n",
        "merged[\"n_predictions\"] = merged[\"preds_norm\"].apply(len)\n",
        "merged[\"multi_predictions\"] = merged[\"n_predictions\"] > 1\n",
        "merged[\"zero_predictions\"] = merged[\"n_predictions\"] == 0\n",
        "\n",
        "def first_matching_pred(gt_norm_list, preds_norm_list, preds_orig_list):\n",
        "    for p_norm, p_orig in zip(preds_norm_list, preds_orig_list):\n",
        "        if any(p_norm == g for g in gt_norm_list):\n",
        "            return p_orig\n",
        "    return None\n",
        "\n",
        "merged[\"matching_pred\"] = merged.apply(lambda r: first_matching_pred(r[\"gt_norm_list\"], r[\"preds_norm\"], r[\"predicted_list\"]), axis=1)\n",
        "\n",
        "# ----------------- Outputs & summary -----------------\n",
        "match_flag_series = merged[[gt_image_col, \"match_any\"]].copy()\n",
        "multi_pred_filenames = merged.loc[merged[\"multi_predictions\"], gt_image_col].tolist()\n",
        "zero_pred_filenames = merged.loc[merged[\"zero_predictions\"], gt_image_col].tolist()\n",
        "\n",
        "total = len(merged)\n",
        "num_matches = int(merged[\"match_any\"].sum())\n",
        "pct = num_matches / total * 100 if total > 0 else 0.0\n",
        "\n",
        "print(f\"Total GT rows: {total}\")\n",
        "print(f\"Images with >=1 matching prediction: {num_matches} ({pct:.2f}%)\")\n",
        "print(f\"Images with multiple predictions (>1): {merged['multi_predictions'].sum()}\")\n",
        "print(f\"Images with zero predictions: {merged['zero_predictions'].sum()}\")\n",
        "\n",
        "# quick sanity-check: show a few rows and their normalized columns\n",
        "print(\"\\nExample rows (image_file, gt_norm_list, predicted_list, preds_norm, match_any):\")\n",
        "print(merged[[gt_image_col, \"gt_norm_list\", \"predicted_list\", \"preds_norm\", \"match_any\"]].head(10).to_string(index=False))\n",
        "\n",
        "# Save full analysis for inspection\n",
        "out_csv = \"gt_vs_preds_analysis_converted_first.csv\"\n",
        "merged.to_csv(out_csv, index=False)\n",
        "print(f\"\\nSaved analysis to: {out_csv}\")\n",
        "\n",
        "# Expose variables for further use: merged, match_flag_series, multi_pred_filenames, zero_pred_filenames\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gpu_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
