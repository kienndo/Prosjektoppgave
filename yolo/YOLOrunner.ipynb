{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG3HQJiC4HMd"
      },
      "source": [
        "# YOLO\n",
        "The goal of this notebook is to do transfer learning of Fishial´s already implemented YOLO model. We do this by using Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WL6B6r54hEQ",
        "outputId": "a8ab933c-694f-4313-d79a-55f4c3de97b6"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLTdW1qq39IM",
        "outputId": "f133fc27-f0cc-482c-8da0-ec42979d7a2d"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import requests\n",
        "import logging\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SKEsQWhvaGcz"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"../data_csv/\"\n",
        "timor_leste_data_path = os.path.join(DATA_DIR, \"timor-leste.csv\") # Annotation info for ground truth\n",
        "images_path = \"../data_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZRSrG-XZbGs",
        "outputId": "83c4dac0-bc02-46c2-9533-c8e4e5e2042e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total annotated images: 603\n",
            "Relevant images 248\n",
            "Unique final JPGs: 217\n"
          ]
        }
      ],
      "source": [
        "# Filter out relevant images\n",
        "relevant_species = ['Alectis ciliaris', 'Aphareus rutilans', 'Caranx ignobilis', 'Caranx lugubris', 'Caranx melampygus', 'Caranx sexfasciatus', 'Chirocentrus dorab', 'Chirocentrus nudus', 'Decapterus macrosoma', 'Elagatis bipinnulata', 'Epinephelus maculatus', 'Epinephelus radiatus', 'Etelis carbunculus', 'Gymnocranius grandoculis', 'Katsuwonus pelamis', 'Lethrinus atkinsoni', 'Lethrinus erythracanthus', 'Lethrinus obsoletus', 'Lethrinus ornatus', 'Lutjanus bohar', 'Lutjanus fulviflamma', 'Lutjanus fulvus', 'Lutjanus gibbus', 'Lutjanus johnii', 'Lutjanus kasmira', 'Lutjanus rivulatus', 'Lutjanus russellii', 'Lutjanus timoriensis', 'Monotaxis grandoculis', 'Psettodes erumei', 'Rastrelliger kanagurta', 'Sardinella albella', 'Scolopsis lineata', 'Scolopsis vosmeri', 'Scomberoides lysan', 'Scomberomorus commerson', 'Seriola dumerili', 'Variola albimarginata']\n",
        "\n",
        "# Read annotation info (Timor-leste)\n",
        "df_tl_ann = pd.read_csv(timor_leste_data_path, encoding=\"utf-8-sig\", header=0, skiprows=1)\n",
        "df_tl_ann = df_tl_ann[[\"image_file\", \"catch_name_en\", \"Species_name\", \"Family\"]]\n",
        "\n",
        "# Filter by species in relevant_species\n",
        "df_filtered = df_tl_ann[df_tl_ann[\"Species_name\"].isin(relevant_species)]\n",
        "\n",
        "# Keep only images that actually exist\n",
        "existing_files = set(os.listdir(images_path))\n",
        "\n",
        "df_filtered = df_filtered[df_filtered[\"image_file\"].isin(existing_files)]\n",
        "\n",
        "# Convert to list of filenames\n",
        "filtered_images= df_filtered[\"image_file\"].tolist()\n",
        "\n",
        "print(\"Total annotated images:\", len(df_tl_ann))\n",
        "print(\"Relevant images\", len(df_filtered))\n",
        "print(\"Unique final JPGs:\", len(set(filtered_images)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "10YcDKvLIXQP",
        "outputId": "0e357904-ebe7-4b7c-e8e1-c939c9d02ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.235 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.234  Python-3.12.12 torch-2.9.1+cpu CPU (12th Gen Intel Core i5-12500)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\runs\\classify\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "ERROR \u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\train... found 9240 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR \u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\valid... found 883 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR \u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\test... found 440 images in 1 classes (requires 2 classes, not 1)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLO11n-cls summary: 86 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 241.478.1 MB/s, size: 29.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\train... 9240 images, 0 corrupt: 100% ━━━━━━━━━━━━ 9240/9240 4.9Kit/s 1.9s0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 27.622.1 MB/s, size: 16.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\valid... 883 images, 0 corrupt: 100% ━━━━━━━━━━━━ 883/883 2.2Kit/s 0.4s<0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\dataset\\valid.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\kiennd\\Desktop\\Prosjektoppgave\\yolo\\runs\\classify\\train2\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\kiennd\\AppData\\Roaming\\Ultralytics\\Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 7.0MB/s 0.1s\n",
            "\u001b[K        1/1         0G     0.9251         16        640: 4% ╸─────────── 25/578 2.8s/it 1:14<25:5150"
          ]
        }
      ],
      "source": [
        "# Load a pretrained YOLO11n model\n",
        "model = YOLO(\"yolo11n-cls.pt\")\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data=\"dataset\",\n",
        "    epochs=1,\n",
        "    imgsz=640,\n",
        "    device=\"cpu\",\n",
        ")\n",
        "\n",
        "# Evaluate the model's performance on the validation set\n",
        "metrics = model.val()\n",
        "\n",
        "display(Image(filename=\"runs/classify/train/results.png\"))\n",
        "display(Image(filename=\"runs/classify/val/confusion_matrix.png\"))\n",
        "\n",
        "# Perform object detection on an image\n",
        "for image in filtered_images[:10]:\n",
        "  results = model(DATA_DIR + \"/timor_leste/\" + image)\n",
        "  results[0].show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
