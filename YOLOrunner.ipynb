{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG3HQJiC4HMd"
      },
      "source": [
        "# YOLO\n",
        "The goal of this notebook is to do transfer learning of Fishial¬¥s already implemented YOLO model. We do this by using Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WL6B6r54hEQ",
        "outputId": "a8ab933c-694f-4313-d79a-55f4c3de97b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.229-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.3.4,>=1.23.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (2.2.6)\n",
            "Requirement already satisfied: matplotlib<=3.10.7,>=3.3.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (3.10.7)\n",
            "Requirement already satisfied: opencv-python<=4.12.0.88,>=4.6.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow<=12.0.0,>=7.1.2 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (12.0.0)\n",
            "Requirement already satisfied: pyyaml<=6.0.3,>=5.3.1 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests<=2.32.5,>=2.23.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (2.32.5)\n",
            "Collecting scipy<=1.16.3,>=1.4.1 (from ultralytics)\n",
            "  Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: torch!=2.4.0,<=2.9.1,>=1.8.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (2.9.1)\n",
            "Requirement already satisfied: torchvision<=0.24.1,>=0.9.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (0.24.1)\n",
            "Requirement already satisfied: psutil<=7.1.3,>=5.8.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from ultralytics) (7.0.0)\n",
            "Collecting polars<=1.35.2,>=0.20.0 (from ultralytics)\n",
            "  Downloading polars-1.35.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ultralytics-thop<=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from matplotlib<=3.10.7,>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Collecting polars-runtime-32==1.35.2 (from polars<=1.35.2,>=0.20.0->ultralytics)\n",
            "  Downloading polars_runtime_32-1.35.2-cp39-abi3-win_amd64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from requests<=2.32.5,>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (2025.10.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (80.9.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<=3.10.7,>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from sympy>=1.13.3->torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kiennd\\appdata\\local\\anaconda3\\envs\\torch_env\\lib\\site-packages (from jinja2->torch!=2.4.0,<=2.9.1,>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.229-py3-none-any.whl (1.1 MB)\n",
            "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.1/1.1 MB 10.5 MB/s  0:00:00\n",
            "Downloading polars-1.35.2-py3-none-any.whl (783 kB)\n",
            "   ---------------------------------------- 0.0/783.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 783.6/783.6 kB 11.1 MB/s  0:00:00\n",
            "Downloading polars_runtime_32-1.35.2-cp39-abi3-win_amd64.whl (41.3 MB)\n",
            "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 2.4/41.3 MB 12.3 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 4.7/41.3 MB 11.9 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 7.1/41.3 MB 11.8 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 9.4/41.3 MB 11.7 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 12.1/41.3 MB 11.6 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 14.4/41.3 MB 11.8 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 16.8/41.3 MB 11.7 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 19.1/41.3 MB 11.6 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 21.5/41.3 MB 11.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 23.9/41.3 MB 11.6 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 26.2/41.3 MB 11.6 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 28.6/41.3 MB 11.7 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 30.9/41.3 MB 11.7 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 33.6/41.3 MB 11.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 35.7/41.3 MB 11.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 38.3/41.3 MB 11.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  40.6/41.3 MB 11.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 41.3/41.3 MB 11.4 MB/s  0:00:03\n",
            "Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
            "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 2.4/38.6 MB 11.2 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 4.7/38.6 MB 11.4 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 7.1/38.6 MB 11.5 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 9.7/38.6 MB 11.4 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 12.1/38.6 MB 11.4 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 14.7/38.6 MB 11.5 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 17.0/38.6 MB 11.5 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 19.4/38.6 MB 11.5 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 22.0/38.6 MB 11.5 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 24.4/38.6 MB 11.5 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 27.0/38.6 MB 11.6 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 28.6/38.6 MB 11.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 30.7/38.6 MB 11.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 32.8/38.6 MB 11.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 34.3/38.6 MB 10.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 35.9/38.6 MB 10.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  37.7/38.6 MB 10.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.6/38.6 MB 10.4 MB/s  0:00:03\n",
            "Downloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: scipy, polars-runtime-32, polars, ultralytics-thop, ultralytics\n",
            "\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   ---------------------------------------- 0/5 [scipy]\n",
            "   -------- ------------------------------- 1/5 [polars-runtime-32]\n",
            "   -------- ------------------------------- 1/5 [polars-runtime-32]\n",
            "   -------- ------------------------------- 1/5 [polars-runtime-32]\n",
            "   ---------------- ----------------------- 2/5 [polars]\n",
            "   ---------------- ----------------------- 2/5 [polars]\n",
            "   ---------------- ----------------------- 2/5 [polars]\n",
            "   ---------------- ----------------------- 2/5 [polars]\n",
            "   ---------------- ----------------------- 2/5 [polars]\n",
            "   ---------------- ----------------------- 2/5 [polars]\n",
            "   -------------------------------- ------- 4/5 [ultralytics]\n",
            "   -------------------------------- ------- 4/5 [ultralytics]\n",
            "   -------------------------------- ------- 4/5 [ultralytics]\n",
            "   -------------------------------- ------- 4/5 [ultralytics]\n",
            "   -------------------------------- ------- 4/5 [ultralytics]\n",
            "   ---------------------------------------- 5/5 [ultralytics]\n",
            "\n",
            "Successfully installed polars-1.35.2 polars-runtime-32-1.35.2 scipy-1.16.3 ultralytics-8.3.229 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLTdW1qq39IM",
        "outputId": "f133fc27-f0cc-482c-8da0-ec42979d7a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file  \n",
            "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\kiennd\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import requests\n",
        "import logging\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SKEsQWhvaGcz"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"data/\"\n",
        "timor_leste_data_path = os.path.join(DATA_DIR, \"timor-leste.csv\") # Annotation info for ground truth\n",
        "images_path = os.path.join(DATA_DIR, \"timor_leste\") # Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZRSrG-XZbGs",
        "outputId": "83c4dac0-bc02-46c2-9533-c8e4e5e2042e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total annotated images: 603\n",
            "Relevant images 248\n",
            "Unique final JPGs: 217\n"
          ]
        }
      ],
      "source": [
        "# Filter out relevant images\n",
        "relevant_species = ['Alectis ciliaris', 'Aphareus rutilans', 'Caranx ignobilis', 'Caranx lugubris', 'Caranx melampygus', 'Caranx sexfasciatus', 'Chirocentrus dorab', 'Chirocentrus nudus', 'Decapterus macrosoma', 'Elagatis bipinnulata', 'Epinephelus maculatus', 'Epinephelus radiatus', 'Etelis carbunculus', 'Gymnocranius grandoculis', 'Katsuwonus pelamis', 'Lethrinus atkinsoni', 'Lethrinus erythracanthus', 'Lethrinus obsoletus', 'Lethrinus ornatus', 'Lutjanus bohar', 'Lutjanus fulviflamma', 'Lutjanus fulvus', 'Lutjanus gibbus', 'Lutjanus johnii', 'Lutjanus kasmira', 'Lutjanus rivulatus', 'Lutjanus russellii', 'Lutjanus timoriensis', 'Monotaxis grandoculis', 'Psettodes erumei', 'Rastrelliger kanagurta', 'Sardinella albella', 'Scolopsis lineata', 'Scolopsis vosmeri', 'Scomberoides lysan', 'Scomberomorus commerson', 'Seriola dumerili', 'Variola albimarginata']\n",
        "\n",
        "# Read annotation info (Timor-leste)\n",
        "df_tl_ann = pd.read_csv(timor_leste_data_path, encoding=\"utf-8-sig\", header=0, skiprows=1)\n",
        "df_tl_ann = df_tl_ann[[\"image_file\", \"catch_name_en\", \"Species_name\", \"Family\"]]\n",
        "\n",
        "# Filter by species in relevant_species\n",
        "df_filtered = df_tl_ann[df_tl_ann[\"Species_name\"].isin(relevant_species)]\n",
        "\n",
        "# Keep only images that actually exist\n",
        "existing_files = set(os.listdir(images_path))\n",
        "\n",
        "df_filtered = df_filtered[df_filtered[\"image_file\"].isin(existing_files)]\n",
        "\n",
        "# Convert to list of filenames\n",
        "filtered_images= df_filtered[\"image_file\"].tolist()\n",
        "\n",
        "print(\"Total annotated images:\", len(df_tl_ann))\n",
        "print(\"Relevant images\", len(df_filtered))\n",
        "print(\"Unique final JPGs:\", len(set(filtered_images)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "10YcDKvLIXQP",
        "outputId": "0e357904-ebe7-4b7c-e8e1-c939c9d02ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.5MB 242.4MB/s 0.0s\n",
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/FISHIAL/dataset, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/FISHIAL/dataset/train... found 3080 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/FISHIAL/dataset/valid... found 883 images in 1 classes (requires 2 classes, not 1)\n",
            "ERROR ‚ùå \u001b[34m\u001b[1mtest:\u001b[0m /content/drive/MyDrive/FISHIAL/dataset/test... found 440 images in 1 classes (requires 2 classes, not 1)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLO11n-cls summary: 86 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 304.1MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 3.1¬±4.1 ms, read: 0.0¬±0.0 MB/s, size: 29.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/FISHIAL/dataset/train... 17 images, 0 corrupt: 1% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 17/3080 1.4s/it 13.1s<1:12:25\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mverify_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0mcheck_file_speeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check image read speeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_cache_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# attempt to load a *.cache file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDATASET_CACHE_VERSION\u001b[0m  \u001b[0;31m# matches current version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mload_dataset_cache_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reduce pickle load time https://github.com/ultralytics/ultralytics/pull/1585\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FISHIAL/dataset/train.cache'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3648183648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_results = model.train(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         self.train_loader = self.get_dataloader(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/classify/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/classify/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mClassificationDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mClassificationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, args, augment, prefix)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_ram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_disk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"disk\"\u001b[0m  \u001b[0;31m# cache images on hard drive as uncompressed *.npy files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# filter out bad images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# file, index, npy, im\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (0.08, 1.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mverify_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTQDM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnf_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                         \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Load a pretrained YOLO11n model\n",
        "model = YOLO(\"yolo11n-cls.pt\")\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data=DATA_DIR+\"dataset\",\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    device=\"cuda\",\n",
        ")\n",
        "\n",
        "# Evaluate the model's performance on the validation set\n",
        "metrics = model.val()\n",
        "\n",
        "display(Image(filename=\"runs/classify/train/results.png\"))\n",
        "display(Image(filename=\"runs/classify/val/confusion_matrix.png\"))\n",
        "\n",
        "# Perform object detection on an image\n",
        "for image in filtered_images[:10]:\n",
        "  results = model(DATA_DIR + \"/timor_leste/\" + image)\n",
        "  results[0].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bn25gMOkrWH"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37l8dyl-6iP_"
      },
      "outputs": [],
      "source": [
        "images_path = os.path.join(DATA_DIR, \"timor_leste\") # Images\n",
        "timor_leste_data_path = os.path.join(DATA_DIR, \"timor-leste.csv\") # Annotation info for ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1psL9FudPhnO"
      },
      "outputs": [],
      "source": [
        "# Read annotation info (Timor-leste)\n",
        "df_tl_ann = pd.read_csv(timor_leste_data_path, encoding=\"utf-8-sig\", header=0, skiprows=1)\n",
        "df_tl_ann = df_tl_ann[[\"image_file\", \"catch_name_en\", \"Species_name\", \"Family\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd9lTfyyBCUH"
      },
      "outputs": [],
      "source": [
        "raw = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "classes = [line.strip() for line in raw.splitlines() if line.strip()]\n",
        "\n",
        "# 2) Format: \"Genus species\" (first word capitalized, others lowercase)\n",
        "def format_name(name: str) -> str:\n",
        "    # Leave codes / single tokens as-is\n",
        "    if \"_\" not in name:\n",
        "        return name\n",
        "\n",
        "    parts = name.split(\"_\")\n",
        "    parts[0] = parts[0].capitalize()          # Genus\n",
        "    parts[1:] = [p.lower() for p in parts[1:]]  # species etc.\n",
        "    return \" \".join(parts)\n",
        "\n",
        "input_species = [format_name(n) for n in classes]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCErfkimQrKQ",
        "outputId": "a523c7de-1e84-4a4b-fa53-e03139f472da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Species found in BOTH input and dataset:\n",
            "[] \n",
            "\n",
            "Species in INPUT but NOT in dataset:\n",
            "['Blacksaddle filefish', 'Blue streak cleaner wrasse', 'Butterfly fish', 'Checkerboard wrasse', \"Clark's anemonefish\", \"Commerson's frogfish\", 'Lionfish', 'Longfin bannerfish', 'Manybar goatfish', 'Moorish idol', 'Pyramid butterflyfish', 'Redtoothed triggerfish', 'Reticulate dascyllus', 'Ribboned sweetlips', 'Sea goldie', 'Sergeant major fish', 'Teira batfish', \"Weber's chromis\"] \n",
            "\n",
            "Species in dataset but NOT in input list:\n",
            "(Showing first 20) ['Barracuda & Jacks/Trevally/Other Scad', 'Barracuda & Jacks/Trevally/Other Scad & Jacks/Trevally/Other Scad', 'Barracuda & Jacks/Trevally/Other Scad & Snapper/seaperch', 'Bream & Emperor & Snapper/seaperch & Unknown & Unknown', 'Bream & Grouper & Unknown', 'Bream & Jacks/Trevally/Other Scad', 'Bream & Jacks/Trevally/Other Scad & Stingrays', 'Bream & Snapper/seaperch', 'Emperor', 'Emperor & Goatfish & Spinefoot & Tuna/Bonito/Other Mackerel', 'Emperor & Jacks/Trevally/Other Scad & Jacks/Trevally/Other Scad & Spinefoot', 'Emperor & Jacks/Trevally/Other Scad & Spinefoot', 'Emperor & Moontail bullseye & Snapper/seaperch & Spinefoot', 'Emperor & Snapper/seaperch', 'Emperor & Snapper/seaperch & Spinefoot', 'Emperor & Snapper/seaperch & Spinefoot & Surgeonfish', 'Emperor & Snapper/seaperch & Unicornfish', 'Emperor & Spinefoot', 'Flying fish & Fusilier & Mackerel scad & Parrotfish & Soldierfish', 'Flying fish & Garfish & Jacks/Trevally/Other Scad']\n"
          ]
        }
      ],
      "source": [
        "registered_species = set(df_tl_ann[\"catch_name_en\"].dropna().astype(str).str.strip().unique())\n",
        "\n",
        "input_species = [\n",
        "    \"Blacksaddle filefish\",\n",
        "    \"Blue streak cleaner wrasse\",\n",
        "    \"Butterfly fish\",\n",
        "    \"Checkerboard wrasse\",\n",
        "    \"Clark's anemonefish\",\n",
        "    \"Commerson's frogfish\",\n",
        "    \"Lionfish\",\n",
        "    \"Longfin bannerfish\",\n",
        "    \"Manybar goatfish\",\n",
        "    \"Moorish idol\",\n",
        "    \"Pyramid butterflyfish\",\n",
        "    \"Redtoothed triggerfish\",\n",
        "    \"Reticulate dascyllus\",\n",
        "    \"Ribboned sweetlips\",\n",
        "    \"Sea goldie\",\n",
        "    \"Sergeant major fish\",\n",
        "    \"Teira batfish\",\n",
        "    \"Weber's chromis\"\n",
        "]\n",
        "\n",
        "input_species = set([s.strip() for s in input_species])\n",
        "\n",
        "# Compare sets\n",
        "intersection = registered_species.intersection(input_species)\n",
        "only_in_input = input_species - registered_species\n",
        "only_in_registered = registered_species - input_species\n",
        "\n",
        "# Print results\n",
        "print(\"Species found in BOTH input and dataset:\")\n",
        "print(sorted(intersection), \"\\n\")\n",
        "\n",
        "print(\"Species in INPUT but NOT in dataset:\")\n",
        "print(sorted(only_in_input), \"\\n\")\n",
        "\n",
        "print(\"Species in dataset but NOT in input list:\")\n",
        "print(f\"(Showing first 20) {sorted(list(only_in_registered))[:20]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WSBO9b9k6EX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Load the TorchScript model\n",
        "model = torch.jit.load('model.ts')\n",
        "\n",
        "# Put model in training mode\n",
        "model.train()\n",
        "\n",
        "# Set up your data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load your new image dataset\n",
        "train_dataset = datasets.ImageFolder('path/to/new/images', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Set up optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.jit.save(model, 'finetuned_model.ts')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
